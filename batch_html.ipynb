{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1Ubqn8WNonAdN8t5TC9UPgWV3HoO3jzGJ",
      "authorship_tag": "ABX9TyO231ANg+o7OIsd3psGB9vH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dipangshuk20/compfox-private/blob/main/batch_html.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-auth google-auth-oauthlib google-auth-httplib2 google-api-python-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5DQ4gHhDeBo",
        "outputId": "532abdd0-59c7-4651-8126-62c6dd211a98"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.9/dist-packages (2.17.1)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.9/dist-packages (1.0.0)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.9/dist-packages (0.1.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.9/dist-packages (2.70.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.9/dist-packages (from google-auth) (1.16.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib) (1.3.1)\n",
            "Requirement already satisfied: httplib2>=0.15.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-httplib2) (0.21.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.9/dist-packages (from google-api-python-client) (2.11.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /usr/local/lib/python3.9/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.20.3)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.9/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.27.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.59.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.9/dist-packages (from httplib2>=0.15.0->google-auth-httplib2) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client) (2022.12.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def html_convert(file):\n",
        "    doc = aw.Document(file)\n",
        "    doc.save(\"/content/h_output.html\")\n",
        "    "
      ],
      "metadata": {
        "id": "KL9cRNIObQ8E"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def html_cleaning(html_list):\n",
        "    g=open(\"/content/cchanged_html.html\",'w+')\n",
        "    for i in html_list:\n",
        "        if \"Aspose\" in i:\n",
        "            i=''\n",
        "            g.write(i)\n",
        "        if \"<img\" in i:\n",
        "            i=''\n",
        "            g.write(i)\n",
        "        else:\n",
        "            g.write(i)\n",
        "    print(\"done html\")\n",
        "    final_str=g.read()\n",
        "    return final_str \n",
        "    "
      ],
      "metadata": {
        "id": "L4p6HMXFbR_c"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def html_root(file):\n",
        "    html_convert(file)\n",
        "    with open(\"/content/h_output.html\",\"r\", encoding=\"utf8\") as file:\n",
        "        soup = BeautifulSoup(file, 'html.parser').prettify()\n",
        "        html_list = soup.split(\"\\n\")\n",
        "    \n",
        "    html_till_now=html_cleaning(html_list)\n",
        "    saaf_safai_num()\n",
        "\n",
        "    gp=open(\"/content/updated_cleaning.html\",\"r\")\n",
        "    ht_s=gp.read()\n",
        "    return ht_s\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "DuXn4zzlbU1f"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "dest_bucket_name='regular_final_html'\n",
        "\n",
        "def upload_blob_from_memory(dest_bucket_name, contents, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "\n",
        "    # The ID of your GCS bucket\n",
        "    # bucket_name = \"your-bucket-name\"\n",
        "\n",
        "    # The contents to upload to the file\n",
        "    # contents = \"these are my contents\"\n",
        "\n",
        "    # The ID of your GCS object\n",
        "    # destination_blob_name = \"storage-object-name\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(dest_bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "    blob.upload_from_string(contents)\n",
        "\n",
        "    print(\n",
        "        f\"{destination_blob_name} with contents {contents} uploaded to {dest_bucket_name}.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "Gw9qkD0ebaC0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RZpei7P5bZ_D"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import glob\n",
        "from bs4 import BeautifulSoup\n",
        "import subprocess\n",
        "import os\n",
        "from tempfile import NamedTemporaryFile"
      ],
      "metadata": {
        "id": "jJDAhEfWDUzk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "lJhh_FL1DA7E"
      },
      "outputs": [],
      "source": [
        "## DEFINE BUCKET _DETAILS\n",
        "# hi\n",
        "project_id = 'compfox-367313'\n",
        "in_bucket_name = 'compfox-htmls-manual'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "# Create a `Client` object\n",
        "storage_client = storage.Client(project=project_id)\n",
        "\n",
        "# Get a reference to the bucket\n",
        "#bucket_name = 'en_banc_2014onwards'\n",
        "in_bucket = storage_client.bucket(in_bucket_name)"
      ],
      "metadata": {
        "id": "e66r4fV9DYfi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aspose-words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeC8V5FmDBdz",
        "outputId": "ba9e0454-6eca-4161-ea81-498ee8ed70f4"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: aspose-words in /usr/local/lib/python3.9/dist-packages (23.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import aspose.words as aw\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "ped3CdQIDk6k"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def html_convert(doc,count):\n",
        "#     doc = aw.Document(doc)#\"ocr_txt_redo.pdf\")\n",
        "#     doc.save(\"h_output_{}.html\".format(count))\n",
        "    "
      ],
      "metadata": {
        "id": "qITNec0MDpuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def html_cleaning(html_list,count):\n",
        "#     g=open(\"cchanged_html_{}.html\".format(count),'w+')\n",
        "#     for i in html_list:\n",
        "#         if \"Aspose\" in i:\n",
        "#             i=''\n",
        "#             g.write(i)\n",
        "#         if \"<img\" in i:\n",
        "#             i=''\n",
        "#             g.write(i)\n",
        "#         else:\n",
        "#             g.write(i)\n",
        "#     print(\"done html\")\n",
        "    "
      ],
      "metadata": {
        "id": "nLlvR00NDrjP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def get_html_list(doc):\n",
        "#   with open(doc,\"r\") as file:\n",
        "#     soup = BeautifulSoup(file, 'html.parser').prettify()\n",
        "#     html_list = soup.split(\"\\n\")\n",
        "#   return html_list\n"
      ],
      "metadata": {
        "id": "65iVmisXHqio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def html_root(doc,count):\n",
        "#     html_convert(doc, count)\n",
        "#     # with open(\"h_output.html\",\"r\", encoding=\"utf8\") as file:\n",
        "#     #     soup = BeautifulSoup(file, 'html.parser').prettify()\n",
        "#     #     html_list = soup.split(\"\\n\")\n",
        "#     html_list=get_html_list(doc)\n",
        "#     html_cleaning(html_list,count)\n",
        "#     gp=open(\"cchanged_html_{}.html\".format(count),\"r\")\n",
        "#     ht_s=gp.read()\n",
        "#     ht_p=saaf_safai_num(ht_s)\n",
        "#     return ht_p\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "yzVqJFfzDsfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def jsonify(l):\n",
        "    import json\n",
        "    with open('batch_for_html.json', 'a', encoding='utf-8') as f:\n",
        "        json.dump(l, f, ensure_ascii=False, indent=4)"
      ],
      "metadata": {
        "id": "OPf20dWFDC61"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def saaf_safai_num():\n",
        "  ## Removes nuber from code html\n",
        "  ok=open(\"/content/cchanged_html.html\",\"r\")\n",
        "  soup=BeautifulSoup(ok.read(), 'html.parser')\n",
        "  for span in soup.find_all('span'):\n",
        "    if any(char.isdigit() for char in span.text):\n",
        "      span.decompose()\n",
        "  with open('/content/updated_cleaning.html', 'w') as f:\n",
        "    f.write(soup.prettify())\n",
        "\n",
        "  return \"done\"\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "r0502ODdbiQW"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove_num(test_debug1)"
      ],
      "metadata": {
        "id": "0U4XbWFCryAs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def remove_num(html_content):\n",
        "  soup=BeautifulSoup(html_content, 'html.parser')\n",
        "  for span in soup.find_all('span'):\n",
        "    if re.match('^[0-9]+$', span.text.strip()):\n",
        "        span.extract()\n",
        "  return soup.prettify()\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "jr_fWuXZq6cG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remove_num(test_debug1)"
      ],
      "metadata": {
        "id": "yyzlqN50r9JH"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from bs4 import BeautifulSoup\n",
        "\n",
        "# def saaf_safai_num(html_content_passed_here):\n",
        "#   ## Removes nuber from code html\n",
        "#   soup=BeautifulSoup(html_content_passed_here, 'html.parser')\n",
        "#   for span in soup.find_all('span'):\n",
        "#     if any(char.isdigit() for char in span.text):\n",
        "#       span.decompose()\n",
        "#   # with open('updated.html', 'w') as f:\n",
        "#   #   f.write(soup.prettify())\n",
        "\n",
        "#   return soup.pretiffy()\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "iqTJxfBjDHiM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pk\n",
        "def convert_to_pdf(x):\n",
        "    name=x.split(\".\")[0]\n",
        "    file = open(name+\".pdf\", 'wb')\n",
        "    for line in open(x, 'rb').readlines():\n",
        "        file.write(line)\n",
        "    file.close()"
      ],
      "metadata": {
        "id": "EnNFjOTCEWHs"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def yopgno(): \n",
        "  cmd = \"pdfinfo /content/ocr_txt_redo.pdf | grep 'Pages' | awk '{print $2}'\" \n",
        "  return os.popen(cmd).read().strip()"
      ],
      "metadata": {
        "id": "HYYjsHZhEt6U"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yopgno()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1st2cqhHOQBp",
        "outputId": "70d1435b-3484-4b63-fa12-4570e27c28c1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import storage\n",
        "dest_bucket_name = \"regular_final_html\"\n",
        "import json\n",
        "def upload_blob_from_memory(dest_bucket_name, contents, destination_blob_name):\n",
        "    \"\"\"Uploads a file to the bucket.\"\"\"\n",
        "\n",
        "    # The ID of your GCS bucket\n",
        "    dest_bucket_name = \"regular_final_html\"\n",
        "\n",
        "    # The contents to upload to the file\n",
        "    # contents = \"these are my contents\"\n",
        "\n",
        "    # The ID of your GCS object\n",
        "    # destination_blob_name = \"storage-object-name\"\n",
        "\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(dest_bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "\n",
        "    blob.upload_from_string(json.dumps(contents))\n",
        "\n",
        "    print(\n",
        "        f\"{destination_blob_name} with contents {contents} uploaded to {dest_bucket_name}.\"\n",
        "    )"
      ],
      "metadata": {
        "id": "FLuv-sU1EH1F"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# version 1 with no split"
      ],
      "metadata": {
        "id": "wR51f0h7fqLY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #v1\n",
        "# import os\n",
        "# #thalaiva \n",
        "# new_json=[]\n",
        "# line_count=1\n",
        "# done_name=[]\n",
        "# json_file='new_json_04.json'\n",
        "# skip_func = False\n",
        "# for blob in bucket.list_blobs():\n",
        "#     if blob.name.endswith('.pdf'):\n",
        "#       if blob.name == '2019_08_12_Macedo, Maricela.pdf':\n",
        "#         skip_func = False\n",
        "#       if skip_func!=True:\n",
        "#         done_name.append(blob.name)\n",
        "#         print(blob.name)\n",
        "#         pdf_blob = blob.download_as_string()\n",
        "#         g=open('ocr_txt_redo.txt', 'wb')\n",
        "#         g.write(pdf_blob)\n",
        "#         convert_to_pdf('ocr_txt_redo.txt')\n",
        "#         html_root()\n",
        "#         # break\n",
        "#         h= open('/content/cchanged_html.html','r')\n",
        "#         saaf_safai_num(remove_num(h.read()))\n",
        "#         hmm=open('/content/cchanged_html.html','r')\n",
        "#         html_content_bro=hmm.read()\n",
        "\n",
        "#         upload_blob_from_memory('regular_final_html',html_content_bro,blob.name)\n",
        "#         new_json.append({blob.name:html_content_bro})\n",
        "#         hmm.close()\n",
        "#         # line_count+=1\n",
        "#         # file_num=1\n",
        "#         # s=open(r\"/content/drive/MyDrive/html_batch_compfox/json_30.json\",'a')\n",
        "#         # s.write(str(new_json))\n",
        "#           # new_json=[]\n",
        "\n",
        "\n",
        "\n",
        "#         # output_dir = '/content/html_test'\n",
        "#         # html_root()\n",
        "#         # html_path = convert_pdf_to_html_v2(\"/content/extract_for_html.pdf\", output_dir)\n",
        "#         # pages=int(yopgno())\n",
        "#         # merge_output_path=\"/content/merged_html.html\"\n",
        "#         # soup = BeautifulSoup(\"<html><body></body></html>\", \"html.parser\")\n",
        "#         # html_files = glob.glob('/content/drive/MyDrive/html_test/*.html')\n",
        "#         # for i in range(1,pages):\n",
        "#         #   gf=open(f\"/content/drive/MyDrive/html_test/extract_for_html-{i}.html\",\"r\")\n",
        "#         #   content=gf.read()\n",
        "#         #   body = BeautifulSoup(content, \"html.parser\").body\n",
        "\n",
        "#         #   if body is not None:\n",
        "#         #     div = body.find('div')\n",
        "#         #     if div is not None:\n",
        "#         #       soup.body.append(div)\n",
        "#         #     else:\n",
        "#         #       soup.body.append(body_contents = body.contents)\n",
        "#         # with open(merge_output_path, \"w\") as f:\n",
        "#         #     f.write(str(soup))\n",
        "#         # print(\"done merging\")\n",
        "#         # clean_html()"
      ],
      "metadata": {
        "id": "SPF2XPmCbHek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(new_json)"
      ],
      "metadata": {
        "id": "pfrbuViXbzsA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ypYBsG3fbzor"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CFXetmjIbzmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XueNV-1Pbzjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRCPBVpVbzhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSmY7iJYbzeZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hsgx7sb0bza2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PG40LjFLbzXh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install PyPDF2"
      ],
      "metadata": {
        "id": "v7MoPXVuKzu4",
        "outputId": "352c7f6c-ef1a-47e8-8eb6-90d704c542c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=3.10.0.0 in /usr/local/lib/python3.9/dist-packages (from PyPDF2) (4.5.0)\n",
            "Installing collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLcMye-WGv3p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        " Used pikepdf\n",
        "```\n",
        "\n",
        " Code to split pdf "
      ],
      "metadata": {
        "id": "r02oGKcEbcNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pikepdf"
      ],
      "metadata": {
        "id": "OSFgUkB3cLXi",
        "outputId": "004bdf72-9d03-4b45-978e-9b5c80794af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pikepdf in /usr/local/lib/python3.9/dist-packages (7.1.2)\n",
            "Requirement already satisfied: Pillow>=9.0 in /usr/local/lib/python3.9/dist-packages (from pikepdf) (9.5.0)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.9/dist-packages (from pikepdf) (4.9.2)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.9/dist-packages (from pikepdf) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pikepdf) (23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pikepdf import Pdf\n",
        "# a dictionary mapping PDF file to original PDF's page range\n",
        "file2pages = {\n",
        "    0: [0, 5], # 1st splitted PDF file will contain the pages from 0 to 9 (9 is not included)\n",
        "    1: [5, 10], # 2nd splitted PDF file will contain the pages from 9 (9 is included) to 11\n",
        "    2: [10, 15],\n",
        "    3:[15,20],\n",
        "    4:[20,25],\n",
        "    5:[25,30],# 3rd splitted PDF file will contain the pages from 11 until the end or until the 100th page (if exists)\n",
        "}\n",
        "\n",
        "def split_pdf_samunder(pdf_name):\n",
        "# the target PDF document to split\n",
        "# filename = \"diagnostics-12-00915-v2 (3).pdf\"\n",
        "# make the new splitted PDF files\n",
        "# load the PDF file\n",
        "  pdf = Pdf.open(pdf_name)\n",
        "  new_pdf_files = [ pdf.new() for i in file2pages ]\n",
        "# the current pdf file index\n",
        "  new_pdf_index = 0\n",
        "# iterate over all PDF pages\n",
        "  for n, page in enumerate(pdf.pages):\n",
        "      if n in list(range(*file2pages[new_pdf_index])):\n",
        "        new_pdf_files[new_pdf_index].pages.append(page)\n",
        "        # print(f\"[*] Assigning Page {n} to the file {new_pdf_index}\")\n",
        "      else:\n",
        "        name, ext = os.path.splitext(pdf_name)\n",
        "        output_filename = f\"{name}-{new_pdf_index}.pdf\"\n",
        "        # save the PDF file\n",
        "        new_pdf_files[new_pdf_index].save(output_filename)\n",
        "        # print(f\"[+] File: {output_filename} saved.\")\n",
        "        # go to the next file\n",
        "        new_pdf_index += 1\n",
        "        # add the `n` page to the `new_pdf_index` file\n",
        "        new_pdf_files[new_pdf_index].pages.append(page)\n",
        "        # print(f\"[*] Assigning Page {n} to the file {new_pdf_index}\")\n",
        "\n",
        "\n",
        "  name, ext = os.path.splitext(pdf_name)\n",
        "  output_filename = f\"{name}-{new_pdf_index}.pdf\"\n",
        "  new_pdf_files[new_pdf_index].save(output_filename)\n",
        "  print(f\"[+] File: {output_filename} saved.\")\n",
        "\n",
        "  return pdf.pages\n"
      ],
      "metadata": {
        "id": "2MpCHIgWbe0u"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version 2: with pdf split added "
      ],
      "metadata": {
        "id": "9hmuHS_wfbv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pikepdf"
      ],
      "metadata": {
        "id": "YdwCbW7OMv3S",
        "outputId": "53f87cf6-2537-4a8b-ccc5-b9a04e0af3f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pikepdf in /usr/local/lib/python3.9/dist-packages (7.1.2)\n",
            "Requirement already satisfied: deprecation in /usr/local/lib/python3.9/dist-packages (from pikepdf) (2.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from pikepdf) (23.0)\n",
            "Requirement already satisfied: Pillow>=9.0 in /usr/local/lib/python3.9/dist-packages (from pikepdf) (9.5.0)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.9/dist-packages (from pikepdf) (4.9.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pikepdf import Pdf\n",
        "# a dictionary mapping PDF file to original PDF's page range\n",
        "file2pages = {\n",
        "    0: [0, 5], # 1st splitted PDF file will contain the pages from 0 to 9 (9 is not included)\n",
        "    1: [5, 10], # 2nd splitted PDF file will contain the pages from 9 (9 is included) to 11\n",
        "    2: [10, 15],\n",
        "    3:[15,20],\n",
        "    4:[20,25],\n",
        "    5:[25,30],# 3rd splitted PDF file will contain the pages from 11 until the end or until the 100th page (if exists)\n",
        "}\n",
        "\n",
        "def split_pdf_samunder(pdf_name):\n",
        "# the target PDF document to split\n",
        "# filename = \"diagnostics-12-00915-v2 (3).pdf\"\n",
        "# make the new splitted PDF files\n",
        "# load the PDF file\n",
        "  pdf = Pdf.open(pdf_name)\n",
        "  new_pdf_files = [ pdf.new() for i in file2pages ]\n",
        "# the current pdf file index\n",
        "  new_pdf_index = 0\n",
        "# iterate over all PDF pages\n",
        "  for n, page in enumerate(pdf.pages):\n",
        "      if n in list(range(*file2pages[new_pdf_index])):\n",
        "        new_pdf_files[new_pdf_index].pages.append(page)\n",
        "        # print(f\"[*] Assigning Page {n} to the file {new_pdf_index}\")\n",
        "      else:\n",
        "        name, ext = os.path.splitext(pdf_name)\n",
        "        output_filename = f\"{name}-{new_pdf_index}.pdf\"\n",
        "        # save the PDF file\n",
        "        new_pdf_files[new_pdf_index].save(output_filename)\n",
        "        # print(f\"[+] File: {output_filename} saved.\")\n",
        "        # go to the next file\n",
        "        new_pdf_index += 1\n",
        "        # add the `n` page to the `new_pdf_index` file\n",
        "        new_pdf_files[new_pdf_index].pages.append(page)\n",
        "        # print(f\"[*] Assigning Page {n} to the file {new_pdf_index}\")\n",
        "\n",
        "\n",
        "  name, ext = os.path.splitext(pdf_name)\n",
        "  output_filename = f\"{name}-{new_pdf_index}.pdf\"\n",
        "  new_pdf_files[new_pdf_index].save(output_filename)\n",
        "  print(f\"[+] File: {output_filename} saved.\")\n",
        "\n",
        "  return len(pdf.pages)\n"
      ],
      "metadata": {
        "id": "I4QAvKD4f7wS"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "htmls={}\n",
        "import json\n",
        "def get_merge_html(num_of_pdfs):\n",
        "  for i in range(0,num_of_pdfs):\n",
        "    htmls[i]=html_root(\"/content/ocr_txt_redo-{}.pdf\".format(i))\n",
        "    ob=open(\"obj.json\",\"w\")\n",
        "    ob.write(json.dumps(htmls))\n",
        "  return htmls\n"
      ],
      "metadata": {
        "id": "zeNc-h8ef5wy"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "  \n"
      ],
      "metadata": {
        "id": "2M51Du0EMc2a"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "done_html_v1=['yeah']"
      ],
      "metadata": {
        "id": "cxgxWomgMYHp"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xhlaPAQFNBwl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "#thalaiva\n",
        "new_json=[]\n",
        "line_count=1\n",
        "done_html_v2=[]\n",
        "json_file='new_json_27.json'\n",
        "for blob in in_bucket.list_blobs():\n",
        "    if blob.name.endswith('.pdf'):\n",
        "        if blob.name not in done_html_v1:\n",
        "          done_html_v2.append(blob.name)\n",
        "          print(blob.name)\n",
        "          \n",
        "          pdf_blob = blob.download_as_string()\n",
        "          g=open('/content/ocr_txt_redo.txt', 'wb')\n",
        "          g.write(pdf_blob)\n",
        "          convert_to_pdf('/content/ocr_txt_redo.txt')\n",
        "          # time.sleep(3)\n",
        "          num_pages=split_pdf_samunder('/content/ocr_txt_redo.pdf')\n",
        "          print(num_pages)\n",
        "          num_of_blocks=int(num_pages/5)+1\n",
        "          # num_pages_o=yopgno()\n",
        "          html_content_bro=get_merge_html(num_of_blocks)\n",
        "          # print(html_content_bro)\n",
        "          # json_str = json.dumps(html_content_bro)\n",
        "\n",
        "          # html_root()\n",
        "          # # break\n",
        "          # h= open('/content/cchanged_html.html','r')\n",
        "          # saaf_safai_num(h.read())\n",
        "          # hmm=open('/content/cchanged_html.html','r')\n",
        "          # html_content_bro=hmm.read()\n",
        "          upload_blob_from_memory('regular_final_html',html_content_bro,blob.name)\n",
        "          new_json.append({blob.name:html_content_bro})\n",
        "          \n",
        "            # new_json=[]\n",
        "  \n",
        "  \n",
        "  \n",
        "        \n",
        "        # output_dir = '/content/html_test'\n",
        "        # html_root()\n",
        "        # html_path = convert_pdf_to_html_v2(\"/content/extract_for_html.pdf\", output_dir)\n",
        "        # pages=int(yopgno())\n",
        "        # merge_output_path=\"/content/merged_html.html\"\n",
        "        # soup = BeautifulSoup(\"<html><body></body></html>\", \"html.parser\")\n",
        "        # html_files = glob.glob('/content/drive/MyDrive/html_test/*.html')\n",
        "        # for i in range(1,pages):\n",
        "        #   gf=open(f\"/content/drive/MyDrive/html_test/extract_for_html-{i}.html\",\"r\")\n",
        "        #   content=gf.read()\n",
        "        #   body = BeautifulSoup(content, \"html.parser\").body\n",
        "\n",
        "        #   if body is not None:\n",
        "        #     div = body.find('div')\n",
        "        #     if div is not None:\n",
        "        #       soup.body.append(div)\n",
        "        #     else:\n",
        "        #       soup.body.append(body_contents = body.contents)\n",
        "        # with open(merge_output_path, \"w\") as f:\n",
        "        #     f.write(str(soup))\n",
        "        # print(\"done merging\")\n",
        "        # clean_html()"
      ],
      "metadata": {
        "id": "S619uAMkD6PI"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dMXQAxuq_ZnN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OFFPmuBmjCQB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}